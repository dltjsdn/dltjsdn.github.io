---
layout: post
title:  "2D 이미지 인지 경진대회 결과 및 분석(HRNet, Mish, CSPNet)"
date:   2020-11-20T14:25:52-05:00
author: Sunwoo Lee
categories: 실습
tags:	jekyll welcome
cover:  "/assets/instacode.png"
---



### 2D 이미지 인지 경진대회 결과 및 분석(HRNet, Mish, CSPNet)

이번 포스팅은 스프링클라우드 주최로 열린 2020 STEP 자율주행인지 알고리즘 평가 플랫폼 경진대회에서 1등을 하여 관련 내용을 적어보았다.

<br/>



![step0](https://user-images.githubusercontent.com/47741696/102361844-064b4400-3ff7-11eb-94a9-99c0bc2c116c.jpg)

문제 2번 2D 시멘틱 세그멘테이션 객체분류에 나갔고 전방 **Camera data data를 이용하여 주차공간, 일반도로, 고속도로 세가지 시나리오에서 차선과 주차장만 찾는** 비교적 쉬운 경진대회였다.

하지만 막상 대회를 참가하고 보니 Training data와 Labeling data를 제공하지 않아서 살짝 당황하였다. 그래서 이번 대회에서는 각 시나리오별 Labeling data를 수집하는게 가장 어려웠다. 



<br/>

#### -Data 수집

<고속도로 : KAIST>

#### ![step1](https://user-images.githubusercontent.com/47741696/102362755-1adc0c00-3ff8-11eb-8fe9-ddb6e9302af8.png)

<br/>

<일반도로 : CamVid>

![step2](https://user-images.githubusercontent.com/47741696/102362760-1c0d3900-3ff8-11eb-94c7-b0adb0935583.png)



<br/>

<주차공간 : 교내 주차장 AVM data labeling >

![step3](https://user-images.githubusercontent.com/47741696/102362764-1ca5cf80-3ff8-11eb-9ed7-5c366caae7ac.png)



각 시나리오별 Data는 위에 그림들처럼 수집을 하였다.  

<br/>

### -연구진행 사항

####  Network : HRNetV2사용

![step4](https://user-images.githubusercontent.com/47741696/102363534-d69d3b80-3ff8-11eb-841e-6b51e649a4ad.jpg)

HRNet(High-resolution networks) 같은 경우는 현재 Segmentation에서 Sota이며 엄청 무겁지만 성능이 아주 잘나오는 알고리즘이다. 말 그대로 High-resolution으로 이루어진 Network이다 Architecture를 보면 학습이 진행될수록 **Layer는 깊어지지만 4개의 Stage가 Resolution을 유지하면서 계속적으로 Convolution을 진행한다.** 이때 각 Layer 전달 단계는 Bottlenect을 사용하거나 간단한 2D Conv를 사용한다. 

`HRNet과 자세한 논문 리뷰 및 코드분석은 따로 올릴 예정이다.`

<br/>

![step6](https://user-images.githubusercontent.com/47741696/102371775-e5d4b700-4001-11eb-920e-15e15aad7145.png)



이것은 Segmentation에 가장 기본적인 구조인 UNet과 HRNet을 비교해본 사진이다. 확실히 HRNet이 High Resolution을 유지함으로 인한 검출 대상에 대한 Contour가 더 명확해졌다. 

<br/>

#### CSPNet

![step7](https://user-images.githubusercontent.com/47741696/102372146-419f4000-4002-11eb-91f0-4347d2793be0.jpg)

HRNet은 High Resolution을 유지하기 때문에 메모리 사용량이 엄청난다. 그래서 메모리를 최적화 시키는것이 정말 중요하다. 그래서 사용한 알고리즘이 CSPNet이다 이번 YOLOV4에서도 강조한 내용으로 **Layer 전달 단계에서 일부 채널은 기존 방식대로 나머지 일부 변형하지 않은 원본으로 전달하여 메모리를 줄인다**.  본 대회에서 CSPNet을 사용하여서 메모리 사용량을 20% 정도 감소 시켰다.

`CSPNet은 간단하면서도 왜 그럴까라는 생각이 많이 드는 알고리즘이다. 따로 정리하고 코드에 적용시켜보는 글을 올려 볼 예정이다.`

<br/>

#### Mish

![step10](https://user-images.githubusercontent.com/47741696/102373052-27199680-4003-11eb-8c6f-00c9c96c9f3a.jpg)

Mish는 pytorch 코드로는 def mish(x) :    return x * tf.nn.tanh( tf.nn.softplus(x)) 로 위 그림처럼 ReLU와는 차이가 있다. 약간의 음수를 허용해서 ReLU보다는 gradient가 더 잘 흐르게 하였다.

```
class MishImplementation(torch.autograd.Function):
    @staticmethod
    def forward(ctx, input):
        result = input * torch.tanh(F.softplus(input))
        ctx.save_for_backward(input)
        return result
    @staticmethod
    def backward(ctx, grad_output):
        i = ctx.saved_variables[0]
        sigmoid_i = torch.sigmoid(i)
        softplus = F.softplus(i)
        sech = 1/ torch.cosh(softplus)
        tanh = torch.tanh(softplus)
        backward = grad_output * (tanh +i * sigmoid_i * (sech**2))
        return backward

class MemoryEfficientMish(nn.Module):
    def forward(self, x):
        return MishImplementation.apply(x)
```

HRNet의 적용을 시켜보려고 하니 메모리가 터지는 현상이 발생하였다. 모델을 더 경량화하기는 싫어서 위에 코드처럼 Mish class를 만들고 **backward = grad_output * (tanh +i * sigmoid_i * (sech2))에 미분값을 직접 넣어 누적이 안되게 하여서 해결**을 했다.

<br/>

![step11](https://user-images.githubusercontent.com/47741696/102373984-27666180-4004-11eb-96dd-2f5aab98fdce.png)

결과물 제출 방식은 Json 파일로 해달라고 해서 Segmentation 결과물을 Clustering 한 뒤 Cluster별 Polygon Vertex 출력하였다. 

<br/>

#### 결과영상

<고속도로>

![highway](https://user-images.githubusercontent.com/47741696/102374466-b83d3d00-4004-11eb-98e3-06b7098ae23b.gif)

<일반도로>

![road](https://user-images.githubusercontent.com/47741696/102374450-b4111f80-4004-11eb-8627-9a3275fe4cf1.gif)

<주차공간>

![parkinglot](https://user-images.githubusercontent.com/47741696/102374458-b70c1000-4004-11eb-8d94-03f4605ce6e8.gif)